{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e492b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Velocity-Aware Geo-Indistinguishability\n",
    "\n",
    "This notebook provides a tour of how to replicate results obtained with the Velocity-Aware Geo-Indistinguishability Mechanism in the Privkit Framework:\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Location Privacy-Preserving Mechanisms (LPPMs) have been proposed to mitigate the risks of privacy disclosure yielded from location sharing. However, due to the nature of this type of data, spatio-temporal correlations can be leveraged by an adversary to extenuate the protections. Moreover, the application of LPPMs at collection time has been limited due to the difficulty in configuring the parameters and in understanding their impact on the privacy level by the end-user. In this work we adopt the velocity of the user and the frequency of reports as a metric for the correlation between location reports. Based on such metric we propose a generalization of Geo-Indistinguishability denoted Velocity-Aware Geo-Indistinguishability (VA-GI). We define a VA-GI LPPM that provides an automatic and dynamic trade-off between privacy and utility according to the velocity of the user and the frequency of reports. This adaptability can be tuned for general use, by using city or country-wide data, or for specific user profiles, thus warranting fine-grained tuning for users or environments. Our results using vehicular trajectory data show that VA-GI achieves a dynamic trade-off between privacy and utility that outperforms previous works. Additionally, by using a Gaussian distribution as estimation for the distribution of the velocities, we provide a methodology for configuring our proposed LPPM without the need for mobility data. This approach provides the required privacy-utility adaptability while also simplifying its configuration and general application in different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed05f07",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "Please consider to cite our publication in your scientific work:\n",
    "\n",
    "```\n",
    "@inproceedings{10.1145/3577923.3583644,\n",
    "    author = {Mendes, Ricardo and Cunha, Mariana and Vilela, Jo\\~{a}o P.},\n",
    "    title = {Velocity-Aware Geo-Indistinguishability},\n",
    "    year = {2023},\n",
    "    isbn = {9798400700675},\n",
    "    publisher = {Association for Computing Machinery},\n",
    "    address = {New York, NY, USA},\n",
    "    url = {https://doi.org/10.1145/3577923.3583644},\n",
    "    doi = {10.1145/3577923.3583644},\n",
    "    booktitle = {Proceedings of the Thirteenth ACM Conference on Data and Application Security and Privacy},\n",
    "    pages = {141–152},\n",
    "    numpages = {12},\n",
    "    location = {<conf-loc>, <city>Charlotte</city>, <state>NC</state>, <country>USA</country>, </conf-loc>},\n",
    "    series = {CODASPY '23}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82044e13",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "This tutorial introduces a quick run down on:\n",
    "- what are scenarios and what are the desired results from considering each subset\n",
    "- how to load each scenario\n",
    "- how to apply each PPM to every scenario\n",
    "- how to visualize the quality loss obtained from every aplication of the ppm on each scenario\n",
    "\n",
    "### What are scenarios?\n",
    "\n",
    "Scenarios are subsets of a dataset that respect certain properties. From those properties, we expect that each subset lead to differnt results, as it can be seen bellow.\n",
    "\n",
    "From *cabspotting* dataset it can be extracted four different scenarios considering user and report velocity ($v_u$ and $v_r$, respectively).\n",
    "\n",
    "- ↑$v_u$, ↑$v_r$ - balance privacy and utility\n",
    "- ↑$v_u$, ↓$v_r$ - favor utility\n",
    "- ↓$v_u$, ↑$v_r$ - favor privacy\n",
    "- ↓$v_u$, ↓$v_r$ - balance privacy and utility\n",
    "\n",
    "The symbols ↑ and ↓ denote a high and a low value, respectively.\n",
    "\n",
    "These scenarios can be found in the corresponding folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "347039db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-27T19:12:22.742778Z",
     "start_time": "2024-11-27T19:12:22.734866Z"
    }
   },
   "source": [
    "import privkit as pk\n",
    "from privkit.utils import constants\n",
    "\n",
    "# id of the dataset\n",
    "file = 'cabspotting'\n",
    "\n",
    "# list of the id's of each scenario\n",
    "scenarios = ['high_vu_high_vr', 'high_vu_low_vr', 'low_vu_high_vr', 'low_vu_low_vr']\n",
    "\n",
    "# list of the id's of each ppm\n",
    "ppms = ['va_gi', 'planar_laplace', 'adaptive', 'clustering']"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "04652324",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading scenarios, applying PPMs and saving results\n",
    "\n",
    "We have seen already how to load datasets and apply Privacy-Preserving Mechanisms.\n",
    "\n",
    "The next step is for every scenario apply every mechanism and save the obtained results, for later visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a13414",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# iterate over every pair of scenario and ppm\n",
    "for scenario in scenarios:\n",
    "    for ppm in ppms:\n",
    "        # load data\n",
    "        location_data = pk.LocationData('{}_{}'.format(scenario, ppm))\n",
    "        location_data.load_data('{}{}/{}.pkl'.format(constants.data_folder, file, scenario))\n",
    "        \n",
    "        # function defined bellow\n",
    "        location_data.data = apply_ppm_to_scenario(ppm, location_data)\n",
    "        \n",
    "        # extract quality loss values from the execution of the ppm\n",
    "        quality_loss_values = location_data.data[constants.QUALITY_LOSS]\n",
    "\n",
    "        # save quality loss values\n",
    "        filepath = '{}{}/{}/'.format(constants.output_folder, file, ppm)\n",
    "        filename = 'ql_{}_e{}'.format(scenario, int(epsilon * 1000))\n",
    "        np.save(filepath + filename, quality_loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482843a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The function *apply_ppm_to_scenario(.)* will generate new columns on our dataset *location_data* with respect to the obfuscated locations computed as well as the quality loss from applying a PPM. We recall that quality loss is a metric to qualify the appliance of a PPM, given by the distance of the obfuscated locations given by the mechanism and the original data.\n",
    "\n",
    "Every result will be saved under the *privkit/output/ppm/* path, where ppm is a variable that will take the ID of every PPM.\n",
    "\n",
    "We now define the function that properly applies the mechanism, and return a modified dataset with the obfuscated location calculated as well as the quality loss resulting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076939f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_ppm_to_scenario(ppm, location_data):\n",
    "    # privacy parameter to be used in the appliance of the PPMs\n",
    "    epsilon = 0.016\n",
    "    \n",
    "    if ppm == 'planar_laplace':\n",
    "        planar_laplace = pk.PlanarLaplace(epsilon=epsilon)\n",
    "        return planar_laplace.execute(location_data)\n",
    "\n",
    "    elif ppm == 'clustering':\n",
    "        # Clustering Geo-Ind additional parameters\n",
    "        r = np.log(4)/epsilon\n",
    "        \n",
    "        clustering = pk.ClusteringGeoInd(r=r, epsilon=epsilon)\n",
    "        return clustering.execute(location_data)\n",
    "\n",
    "    elif ppm == 'adaptive':\n",
    "        # Adaptive Geo-Ind additional parameters\n",
    "        ws = 2\n",
    "        delta1 = 124.29\n",
    "        delta2 = 428.56\n",
    "        \n",
    "        adaptive = pk.AdaptiveGeoInd(epsilon=epsilon, ws=ws, delta1=delta1, delta2=delta2)\n",
    "        return adaptive.execute(location_data)\n",
    "\n",
    "    elif ppm == 'va_gi':\n",
    "        # VA-GI additional parameter\n",
    "        m = 10\n",
    "    \n",
    "        va_gi = pk.VAGI(epsilon=epsilon, m=m)\n",
    "        return va_gi.execute(location_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0293d96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are, of course, multiple ways of achieving the same results. It is possible to use parallelism on each scenario and/or on each mechanism since they are independent, i.e. every iteration of the double for-loop can be done concurrently. Such would result in lower execution time, but we won't cover that in this tutorial for the sake of simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974baf3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71573af5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now present a simple script that generates a *matplotlib* box plot graph, showing the behavior of each scenario under the different PPMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c536ed8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scenarios labels\n",
    "scenarios_labels = [r'$\\uparrow v_u \\downarrow v_r$', \n",
    "                    r'$\\downarrow v_u \\downarrow v_r$', \n",
    "                    r'$\\uparrow v_u \\uparrow v_r$', \n",
    "                    r'$\\downarrow v_u \\uparrow v_r$']\n",
    "\n",
    "# ppms colors\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "# initialize four subplots: one for each scenario\n",
    "plt.subplots(1, 4, sharey=True)\n",
    "\n",
    "# iterate over every scenario\n",
    "for index, (scenario, scenario_label) in enumerate(zip(scenarios, scenarios_labels)):\n",
    "    plt.subplot(1, 4, index + 1)\n",
    "\n",
    "    # load quality loss from every PPM\n",
    "    ql_data = [None] * 4\n",
    "    for ppm_index, ppm in enumerate(ppms):\n",
    "        ql_data[ppm_index] = np.load('{}{}/cabspotting/ql_{}_e{}.npy'.format(constants.output_folder, ppm, scenario, int(epsilon*1000)))\n",
    "\n",
    "    # generate boxplots\n",
    "    boxplots = [None] * 4\n",
    "    for ppm_index, ppm in enumerate(ppms):\n",
    "        boxplots[ppm_index] = plt.boxplot(ql_data[ppm_index], positions=[-1 + ppm_index*2/3], widths=0.20, notch=True, patch_artist=True, showfliers=False)\n",
    "\n",
    "    # set different colors to different PPMs\n",
    "    for plot, color in zip(boxplots, colors):\n",
    "        for patch in plot['boxes']:\n",
    "            patch.set_facecolor(color)\n",
    "\n",
    "    # set scenario label as well as additional graph settings\n",
    "    plt.xticks(np.arange(0, 2, 2), [scenario_label])\n",
    "    plt.axis(xmin=-2, xmax=2)\n",
    "    plt.xlim([-1-2/3, 1+2/3])\n",
    "    plt.ylim([0, 800])\n",
    "    plt.grid(True)\n",
    "\n",
    "# add y label\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.ylabel('Quality Loss (m)')\n",
    "\n",
    "# add legend\n",
    "handles = []\n",
    "for color, ppm in zip(colors, ppms_labels):\n",
    "    handles.append(mpatches.Patch(color=color, label=ppm))\n",
    "plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "# stick the four subplots together\n",
    "plt.subplots_adjust(wspace=.0)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
